{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87759b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757724ba",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162f823e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para_count = []\n",
    "sntc_count = []\n",
    "word_count = []\n",
    "language = []\n",
    "source = []\n",
    "\n",
    "for i in range(17):\n",
    "    data = pd.read_csv('data/data_' + str(i) + '.csv', usecols=['language', 'paragraphs_count', 'sentences_count', 'source', 'words_count'],\n",
    "                      dtype = {'language': str, 'paragraphs_count': str, 'sentences_count': str, 'source': str, 'words_count': str})\n",
    "    para_count += [data.paragraphs_count.values]\n",
    "    sntc_count += [data.sentences_count.values]\n",
    "    word_count += [data.words_count.values]\n",
    "    language += [data.language.values]\n",
    "    source += [data.source.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aef7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into arrays and string\n",
    "para_count = np.concatenate(para_count, axis=0).astype(str)\n",
    "sntc_count = np.concatenate(sntc_count, axis=0).astype(str)\n",
    "word_count = np.concatenate(word_count, axis=0).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4a3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string list to array\n",
    "language = np.concatenate(language, axis=0)\n",
    "source = np.concatenate(source, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868f705",
   "metadata": {},
   "source": [
    "**Average Counts**\n",
    "\n",
    "We have to further clean our data as well, for example in `para_count`, we had a date appear in the column but since this is a small proportion of the data, we remove it. Similarly, `sntc_count` has some websites in it so we again only keep the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a4156c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.136828435875078"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of paragraphs\n",
    "para_count = pd.to_numeric(para_count, errors='coerce')\n",
    "np.nanmean(para_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4934078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.224798025040773"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of sentences\n",
    "sntc_count = pd.to_numeric(sntc_count, errors='coerce')\n",
    "np.nanmean(sntc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285e73aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522.7987642759947"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average word count\n",
    "word_count = word_count.astype(float)\n",
    "np.nanmean(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f6ae2",
   "metadata": {},
   "source": [
    "We can see that we have on average 18 paragraphs per article, 23 sentences and 522 words per article. Now, we don't know how the AYLIEN API defines each paragraph to be, i.e. would a caption be a paragraph so we take this with a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981be67",
   "metadata": {},
   "source": [
    "**Language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b40763c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    1673351\n",
       "1           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(language).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ff483",
   "metadata": {},
   "source": [
    "We can see that we have mainly english articles but two articles with the number 1 as language. We would want to investigate these two articles to ensure that they in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baece9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 419355, 1635730]),)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(language == '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab65eb",
   "metadata": {},
   "source": [
    "So, we'll look into the 419355th and 1635730th articles once we load them in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034feca",
   "metadata": {},
   "source": [
    "**Source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b26890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dailymail.co.uk       97356\n",
       "reuters.com           90420\n",
       "yahoo.com             85906\n",
       "indiatimes.com        50433\n",
       "urdupoint.com         42043\n",
       "                      ...  \n",
       "sozcu.com.tr              1\n",
       "mundodeportivo.com        1\n",
       "20minutes.fr              1\n",
       "zeit.de                   1\n",
       "texas.gov                 1\n",
       "Length: 429, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(source).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f56a30",
   "metadata": {},
   "source": [
    "We can see that the top 5 sources are Daily Mail UK, Reuters, Yahoo, India Times, Urdu Point. This helps to better understand where our articles are coming from and our scope will have to be widened to consider the bias globally rather than in the United States since we would not have sufficient articles from only the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0a5c1",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "\n",
    "Now, for our purposes, we are only interested in the `body` and the `published_at` columns. Hence, we get a DataFrame with just those two columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e498bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = []\n",
    "dates = []\n",
    "\n",
    "for i in range(17):\n",
    "    data = pd.read_csv('data/data_' + str(i) + '.csv', usecols=['body', 'published_at'])\n",
    "    body += [data.body.values]\n",
    "    dates += [data.published_at.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a1e5337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_at</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>On Sunday, British Prime Minister Boris Johnso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>NSW has now recorded 18 COVID-19 deaths as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>ChandigarhWith shops and manufacturing units c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>Chandigarh The 23-year-old man, discharged fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>CHANDIGARH The stillness which had become so m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  published_at                                               body\n",
       "0   2020-04-05  On Sunday, British Prime Minister Boris Johnso...\n",
       "1   2020-04-05  NSW has now recorded 18 COVID-19 deaths as the...\n",
       "2   2020-04-05  ChandigarhWith shops and manufacturing units c...\n",
       "3   2020-04-05  Chandigarh The 23-year-old man, discharged fro...\n",
       "4   2020-04-05  CHANDIGARH The stillness which had become so m..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'published_at': np.concatenate(dates, axis=0), 'body': np.concatenate(body, axis=0)})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a5769f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673356, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609fcc36",
   "metadata": {},
   "source": [
    "The next step we want is to organize by dates since the data did not come in chronological order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0339ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['published_at'].apply(lambda x: str(x)[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de14f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-04    421719\n",
       "2020-03    356982\n",
       "2020-05    312505\n",
       "2020-06    245143\n",
       "2020-07    243827\n",
       "2020-02     72057\n",
       "2020-01     21102\n",
       "2019-12         8\n",
       "2019-11         8\n",
       "nan             3\n",
       "4               1\n",
       "2               1\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b3b9d",
   "metadata": {},
   "source": [
    "From this, we can see that we do not have a lot of data for 2019 since there are only 8 articles. We also have some odd values, i.e. `nan`, `4`, `2`. This limits our analysis as we will be now comparing January 2020 until July 2020. \n",
    "\n",
    "First, we start with removing the null values, the 4 and the 2. We can also remove 2019 data since it is not suficient enough and we will start our exploration in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2353197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to drop\n",
    "drop_lst = ['nan', '4', '2', '2019-11', '2019-12']\n",
    "  \n",
    "# Drop rows that sastisfy those values\n",
    "df = df[df.date.isin(drop_lst) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eefad83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-04    421719\n",
       "2020-03    356982\n",
       "2020-05    312505\n",
       "2020-06    245143\n",
       "2020-07    243827\n",
       "2020-02     72057\n",
       "2020-01     21102\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check data\n",
    "df.date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0ab01",
   "metadata": {},
   "source": [
    "We also check to see if our body values have any missing data. If we have any nulls, we would drop the values since there is no way to impute a body value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "808d7eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2081a00",
   "metadata": {},
   "source": [
    "Now that our data is the way we want it to be, we continue with some text cleaning for the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "987f09e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On Sunday, British Prime Minister Boris Johnson was hospitalized \"for tests\" because of \"persistent\" COVID-19 symptoms\\xa010 days\\xa0after he tested positive, CNN reports.\\xa0\\nJohnson reportedly went to the unspecified London hospital after his doctor advised him to do so. A press release from his office called the\\xa0move\\xa0\"precautionary.\"\\xa0\\nOn March 26, Johnson revealed he had tested positive and that he had been dealing with symptoms since that date. Britain had gone into lockdown two days earlier.\\nSince the 26th, Johnson has been quarantined at his Downing Street residence. He is the first known world leader to have contracted the virus.\\xa0\\nRoughly a month ago, right around the time the U.K. started dealing with an outbreak, Johnson garnered media coverage for saying he\\'d shook hands with coronavirus patients during a hospital visit. \\xa0\\n\"I shook hands with everybody, you will be pleased to know, and I continue to shake hands,\" Johnson said during a press conference that took place on March 3. His positive test was registered 23 days later.\\xa0\\nOn Saturday, Johnson\\'s fiancée, Carrie Symonds, tweeted out that she\\'d spent a week in bed with coronavirus symptoms. She had not officially been tested for the disease, but said she felt \"stronger\" and \"on the mend\" following the week of rest:'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view one article\n",
    "df.body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf759c1",
   "metadata": {},
   "source": [
    "Now, From this article, we can see that there are some newlines, so we'll apply the following preprocessing steps:\n",
    "1. Remove unicode characters\n",
    "2. Remove new line characters\n",
    "3. Convert all words to lowercase \n",
    "4. Remove any punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1c4ba",
   "metadata": {},
   "source": [
    "First, we check if there are any NA values in our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80610c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    line = unicodedata.normalize(\"NFKD\", s)\n",
    "    line = line.rstrip('\\n').lower()\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4492c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.body = df.body.astype('string')\n",
    "df.body = df.body.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e91eaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on sunday british prime minister boris johnson was hospitalized for tests because of persistent covid19 symptoms 10 days after he tested positive cnn reports \\njohnson reportedly went to the unspecified london hospital after his doctor advised him to do so a press release from his office called the move precautionary \\non march 26 johnson revealed he had tested positive and that he had been dealing with symptoms since that date britain had gone into lockdown two days earlier\\nsince the 26th johnson has been quarantined at his downing street residence he is the first known world leader to have contracted the virus \\nroughly a month ago right around the time the uk started dealing with an outbreak johnson garnered media coverage for saying hed shook hands with coronavirus patients during a hospital visit  \\ni shook hands with everybody you will be pleased to know and i continue to shake hands johnson said during a press conference that took place on march 3 his positive test was registered 23 days later \\non saturday johnsons fiancée carrie symonds tweeted out that shed spent a week in bed with coronavirus symptoms she had not officially been tested for the disease but said she felt stronger and on the mend following the week of rest'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check example of cleaned text\n",
    "df.body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbaf580",
   "metadata": {},
   "source": [
    "Now that our data is clean, we use word2vec to get embeddings on our words. We want monthly embeddings, so we first split by months and then save the individual csv files so that we can work with the month data that we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9fa12",
   "metadata": {},
   "source": [
    "### Split by Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "389652fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan = df[df.date == '2020-01'].reset_index()\n",
    "feb = df[df.date == '2020-02'].reset_index()\n",
    "march = df[df.date == '2020-03'].reset_index()\n",
    "april = df[df.date == '2020-04'].reset_index()\n",
    "may = df[df.date == '2020-05'].reset_index()\n",
    "june = df[df.date == '2020-06'].reset_index()\n",
    "july = df[df.date == '2020-07'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17fcdf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28',\n",
       "       '2020-01-27', '2020-01-26', '2020-01-25', '2020-01-24',\n",
       "       '2020-01-23', '2020-01-22', '2020-01-21', '2020-01-20',\n",
       "       '2020-01-19', '2020-01-18', '2020-01-17', '2020-01-16',\n",
       "       '2020-01-15', '2020-01-14', '2020-01-13', '2020-01-12',\n",
       "       '2020-01-11', '2020-01-10', '2020-01-09', '2020-01-08',\n",
       "       '2020-01-07', '2020-01-06', '2020-01-05', '2020-01-04',\n",
       "       '2020-01-03', '2020-01-02', '2020-01-01'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.published_at.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67492300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-05-31', '2020-05-30', '2020-05-29', '2020-05-28',\n",
       "       '2020-05-27', '2020-05-26', '2020-05-25', '2020-05-24',\n",
       "       '2020-05-23', '2020-05-22', '2020-05-21', '2020-05-20',\n",
       "       '2020-05-19', '2020-05-18', '2020-05-17', '2020-05-16',\n",
       "       '2020-05-15', '2020-05-14', '2020-05-13', '2020-05-12',\n",
       "       '2020-05-11', '2020-05-10', '2020-05-09', '2020-05-08',\n",
       "       '2020-05-07', '2020-05-06', '2020-05-05', '2020-05-04',\n",
       "       '2020-05-03', '2020-05-02', '2020-05-01'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.published_at.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad972a8",
   "metadata": {},
   "source": [
    "For both of these months, we have data from dates at the beginning of the month until the end of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402287bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.to_csv('months/jan.csv')\n",
    "feb.to_csv('months/feb.csv')\n",
    "march.to_csv('months/mar.csv')\n",
    "april.to_csv('months/apr.csv')\n",
    "may.to_csv('months/may.csv')\n",
    "june.to_csv('months/june.csv')\n",
    "july.to_csv('months/july.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
